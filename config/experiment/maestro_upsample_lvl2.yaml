# @package _global_

# maestro_upsample_lvl2

defaults:
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /datamodule: maestro_datamodule.yaml
  - override /model: jukebox_upsampler

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["maestro", "jukebox", "lvl2", "upsample"]

seed: 100

trainer:
  log_every_n_steps: 10
  accumulate_grad_batches: 2
  # profiler: 
  #   _target_: pytorch_lightning.profiler.AdvancedProfiler
  #   dirpath: "/usr/stud/steiger/dev/jukebox_diffusion"
  #   filename: "profiling_results2"
  # max_steps: 100

datamodule:
  root_dir: ${oc.env:MAESTRO_DATASET_DIR}
  num_workers: 10
  batch_size: 10
  sample_length: 131072 # 1.5s

model:
  source_lvl: 2
  target_lvl: 1
  model:
    # 96Mil params
    _target_: src.module.diffusion_attn_unet_1d.DiffusionAttnUnet1D
    io_channels: 64
    cond_channels: 64
    n_attn_layers: 6
    channel_sizes: [128, 128, 128, 256, 256, 256, 256, 512, 512]
  lr: 1e-4
  lr_warmup_steps: 2000
  num_train_timesteps: 1000
  inference_batch_size: 4
  inference_seq_len: 2048
  noise_scheduler:
    _target_: diffusers.PNDMScheduler
    num_train_timesteps: 1000
    beta_start: 1e-4
    beta_end: 0.02
    beta_schedule: linear
  timestep_sampler:
    _target_: src.diffusion.timestep_sampler.TimeConstantSampler
    max_timestep: 1000
  num_inference_steps: 50
  skip_audio_logging: false


logger:
  wandb:
    project: "jukebox_diffusion"
    tags: ${tags}
    # settings:
    #   _target_: wandb.Settings
    #   start_method: "fork"
  tensorboard:
    name: "jukebox_diffusion"
