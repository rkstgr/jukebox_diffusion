# @package _global_

# maestro_unconditional_lvl2_unet_100M.yaml

defaults:
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /datamodule: maestro_datamodule.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["maestro", "jukebox", "lvl2", "unconditional"]

seed: 101

trainer:
  log_every_n_steps: 10
  accumulate_grad_batches: 2

datamodule:
  root_dir: ${oc.env:MAESTRO_DATASET_DIR}
  num_workers: 6
  batch_size: 42
  sample_length: 262144  # ~5.9s

model:
  target_lvl: 2
  model:
    _target_: src.module.sgconv.GConvStackedDiffusion
    input_data_dim: 64
    channels: 16
    bidirectional: true
    dropout: 0.0
    n_layers: 12
    time_emb_dim: 32
  lr: 1e-4
  lr_warmup_steps: 200
  inference_batch_size: 16
  noise_scheduler:
    _target_: diffusers.DPMSolverMultistepScheduler
    num_train_timesteps: 1000
    beta_start: 1e-4
    beta_end: 0.02
    beta_schedule: linear
    solver_order: 3
    prediction_type: epsilon
  timestep_sampler:
    _target_: src.diffusion.timestep_sampler.TimeConstantSampler
    max_timestep: 1000
  num_inference_steps: 80
  generate_unconditional: true
  generate_continuation: false
  skip_audio_logging: false


logger:
  wandb:
    project: "jukebox_diffusion"
    tags: ${tags}
  tensorboard:
    name: "jukebox_diffusion"
