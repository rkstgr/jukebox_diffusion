# @package _global_

defaults:
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /datamodule: acapella_datamodule.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["acapella", "run"]

seed: 500

hydra:
  run:
    dir: ${paths.log_dir}/${task_name}/runs/acapella_lvl0

ckpt_path: ${paths.output_dir}/checkpoints/last.ckpt

trainer:
  max_steps: 200_000

datamodule:
  num_workers: 4
  batch_size: 12
  sample_length: 262144

model:
  _target_: src.model.acapella_diffusion.AcapellaDiffusion
  target_lvl: 0
  model:
    _target_: src.module.sgconv.GConvStackedDiffusion
    input_dim: 64
    cond_dim: 16
    time_emb_dim: 32
    model_dim: 64
    channels: 1
    depth: 8
    timestep_max_index: 1000
    l_max: 32768
  lr: 1e-4
  lr_warmup_steps: 5_000
  lr_cycle_steps: 160_000
  inference_batch_size: 16
  noise_scheduler:
    _target_: diffusers.DPMSolverMultistepScheduler
    num_train_timesteps: 1000
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: linear
    solver_order: 3
    prediction_type: sample
  normalizer_path: "normalizations/acapella_lvl_0.pt"
  timestep_sampler:
    _target_: src.diffusion.timestep_sampler.TimeConstantSampler
    max_timestep: 1000
  num_inference_steps: 50
  generate_unconditional: true
  generate_continuation: false
  log_train_audio: true
  skip_audio_logging: false
  guidance_scales: [1, 5, 10]
  conditioning: # build all possible combinations of conditionings
    gender: ["","Female","Male"]
    language: ["","English","Italian","Persian","Spanish"]
    singer: [""]


logger:
  wandb:
    project: "acapella_diffusion"
    name: "cond_lvl0"
    tags: ${tags}
    id: "cond_lvl0"
  tensorboard:
    name: "acapella_diffusion"
